# -*- coding: utf-8 -*-
"""MindBloom.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1d92v4ROYzL4E_Vxs9aRUwB-IepNCoKPh
"""

!pip install -qU google-generativeai==0.8.5 google-ai-generativelanguage==0.6.15\
langgraph langchain langchain-google-genai openai

import os
import getpass
from langgraph.graph import StateGraph, END
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage
from typing import TypedDict

# Set the environment variable first (in Colab or your local shell)
os.environ["GOOGLE_API_KEY"] = "AIzaSyBX9ru-uviySJCXcah7rl7MW85dsmrP5Nk"

# Then retrieve it correctly
api_key = os.environ.get("GOOGLE_API_KEY")
genai.configure(api_key=api_key)

llm = ChatGoogleGenerativeAI(model = "models/gemini-1.5-flash-latest", temperature = 0.2)

def classify_symptom(state: dict) -> dict:
    prompt = (
        "You are a helpful Mental Health chatbot Assistant.\n"
        "Classify the user's symptoms into one of the following categories:\n"
        "- CMD (Common Mental Disorders)\n"
        "- SMI (Severe Mental Illnesses)\n"
        "- DEVELOPMENTAL (Developmental and Behavioral Disorders)\n"
        "- Perfectly fine\n\n"
        f"User Input: {state['user_input']}\n"
        "Respond with exactly one of the following words: CMD, SMI, DEVELOPMENTAL, or PERFECTLY FINE.\n\n"
        "Example:\n"
        "Input: sad, anxious, hopeless\n"
        "Output: CMD"
    )

    response = llm.invoke([HumanMessage(content=prompt)])
    category = response.content.strip().upper()

    print(f"LLM classifies the symptom as: {category}")
    state["category"] = category
    return state

def symptom_router(state: dict) -> str:
    cat = state.get("category", "").strip().lower()

    if cat == "cmd":
        return "CMD"
    elif cat == "smi":
        return "SMI"
    elif cat == "developmental":
        return "DEVELOPMENTAL"
    else:
        return "FINE"

def CMDAgent(state: dict) -> dict:
  prompt = (
      f"""
      You are a supportive and empathetic mental health assistant specializing in Common Mental Disorders (CMDs), such as anxiety, depression, stress, and related emotional challenges.
      Your goal is to:
     - Recognize possible CMD-related symptoms in user input
     - Provide a short, supportive response, new line for each sentence

     - Offer a coping tip or suggest when professional help may be needed

     User input: "{state['user_input']}"

     Guidelines:
     - Keep your tone gentle, warm, and non-judgmental.
     - Do not give medical advice or make diagnoses.
     - Avoid long answers; be concise and helpful.
     - End with a suggestion or a small mental health tip, if appropriate.

     Example 1:
     Input: "I've been feeling really anxious and can't sleep properly."
     Output: "It sounds like you're going through a tough time. Anxiety can affect both your mind and body. Try deep breathing or grounding exercises, and remember you're not alone."

     Example 2:
     Input: "I feel sad all the time and don't enjoy things anymore."
     Output: "I'm really sorry you're feeling this way. These can be signs of depression. Talking to a trusted friend or a mental health professional might help."

     Respond to the following input:
     "{state['user_input']}"
     """
    )
  response = llm.invoke([HumanMessage(content=prompt)])
  cmd_response = response.content.strip()
  print(f"CMD Agent Response: {cmd_response}")
  state["cmd_response"] = cmd_response
  return state

def SMIAgent(state: dict) -> dict:
  prompt = (
      f"""
      You are a compassionate mental health assistant trained to support users showing signs of Severe Mental Illnesses (SMIs), such as schizophrenia, bipolar disorder, or psychosis-related symptoms.
       Your job is to:
      - Gently acknowledge the user's concerns
      - Suggest professional therapy support where appropriate
      - Ask if the user would like to book a therapy session
      - Be warm, respectful, and non-judgmental, new line for each sentence

     User input: "{state['user_input']}"

     Guidelines:
      - Do not give diagnoses or medical advice
      - Keep your reply under 3 sentences
      - Always offer to help book a therapy session or share a booking link
      - If the input does not indicate a clear SMI symptom, gently recommend talking to someone still

     Example 1:
     Input: "Sometimes I hear voices telling me things."
     Output: "That sounds very difficult, and you're not alone. I strongly encourage you to speak to a licensed mental health professional. Would you like me to help you book an online therapy session?"

     Example 2:
     Input: "I feel like everyone is watching me, and it's hard to focus on anything."
     Output: "That can be overwhelming to deal with. Talking to a mental health expert could really help â€” would you like to book a therapy session now?"

     Respond to the following input:
     "{state['user_input']}"
     """
    )
  response = llm.invoke([HumanMessage(content=prompt)])
  smi_response = response.content.strip()
  print(f"SMI Agent Response: {smi_response}")
  state["smi_response"] = smi_response
  if "book" in smi_response.lower() or "therapy session" in smi_response.lower():
        state["therapy_offer_made"] = True
  return state

def DevelopmentalAgent(state: dict) -> dict:
    prompt = f"""
    You are a friendly and professional assistant trained to support users who may be showing signs of developmental or behavioral disorders, such as ADHD, Autism Spectrum Disorders (ASD), or learning and social difficulties.

    Your tasks:
    - Identify if the user input reflects symptoms of a developmental or behavioral disorder
    - Clearly but compassionately explain that this may require in-person evaluation
    - Emphasize the seriousness of seeking timely professional help
    - Ask the user for their current city or location so you can refer a nearby doctor or clinic for an offline session

    Guidelines:
    - Do not use clinical jargon unless necessary
    - Keep your tone respectful and supportive
    - Response should be clear and 2â€“3 sentences long
    - Always ask for the user's location at the end
    - New Line for each sentence

    Example 1:
    Input: "My child struggles to make eye contact and doesn't respond to their name."
    Output: "This may be a sign of a developmental concern, and it's important to address it early. I recommend an in-person consultation with a developmental specialist. Can you please share your location so I can help find a nearby doctor?"

    Example 2:
    Input: "I have trouble focusing and can't sit still even for a few minutes."
    Output: "That could be a sign of ADHD or another behavioral condition. It's best evaluated in person by a specialist. May I know your city or area to find a nearby clinic for you?"

    Respond to the following input:
    "{state['user_input']}"
    """

    response = llm.invoke([HumanMessage(content=prompt)])
    dev_response = response.content.strip()
    print(f"Developmental Agent Response: {dev_response}")

    state["developmental_response"] = dev_response

    if any(word in dev_response.lower() for word in ["location", "city", "area", "nearby"]):
        state["location_requested"] = True

    return state

from langgraph.graph import StateGraph
from langgraph.graph import END
from typing import TypedDict, Optional
from langchain_core.runnables import RunnableLambda

# Define state schema
class GraphState(TypedDict):
    user_input: str
    category: Optional[str]
    cmd_response: Optional[str]
    smi_response: Optional[str]
    developmental_response: Optional[str]
    response: Optional[str]

# Adapters for your functions

def input_adapter(state: GraphState) -> GraphState:
    return {"user_input": state["user_input"]}

def category_selector(state: GraphState) -> str:
    cat = state["category"].upper()
    if cat == "CMD":
        return "cmd"
    elif cat == "SMI":
        return "smi"
    elif cat == "DEVELOPMENTAL":
        return "developmental"
    else:
        return "default"

# Create the graph
workflow = StateGraph(GraphState)

# Add nodes (use lambda wrappers to match Runnable interface)
workflow.add_node("classify", RunnableLambda(classify_symptom))
workflow.add_node("cmd", RunnableLambda(CMDAgent))
workflow.add_node("smi", RunnableLambda(SMIAgent))
workflow.add_node("developmental", RunnableLambda(DevelopmentalAgent))

# Add edges
workflow.set_entry_point("classify")
workflow.add_conditional_edges(
    "classify",
    category_selector,
    {
        "cmd": "cmd",
        "smi": "smi",
        "developmental": "developmental",
        "default": END,
    }
)
workflow.add_edge("cmd", END)
workflow.add_edge("smi", END)
workflow.add_edge("developmental", END)

# Compile graph
app = workflow.compile()

def run_chat_loop(app):
    print("ðŸ§  Mental Health Assistant\n")
    print("ðŸ‘‹ Hello! I'm here to support you. Let's talk.\n")

    # First input
    user_input = input("You: ")
    state = {"user_input": user_input}
    response = app.invoke(state)

    while True:
        # Pick the response from any agent
        agent_reply = (
            response.get("cmd_response") or
            response.get("smi_response") or
            response.get("developmental_response") or
            response.get("response")
        )

        print(f"\nAssistant: {agent_reply}")

        # Get next user input
        user_input = input("\nYou: ")
        if user_input.lower() in ["exit", "quit", "bye"]:
            print("Assistant: Take care! Remember, you're not alone. ðŸ’š")
            break

        state = {"user_input": user_input}
        response = app.invoke(state)

run_chat_loop(app)